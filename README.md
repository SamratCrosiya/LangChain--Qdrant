# <div align="center">ğŸ“š LangChain + Qdrant RAG System</div>

<div align="center">

![Header](https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=300&section=header&text=Chat%20With%20PDF&fontSize=90&animation=fadeIn&fontAlignY=38&desc=RAG-Powered%20Document%20Intelligence&descAlignY=52&descAlign=50&descSize=20)

[![Typing SVG](https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=28&duration=3000&pause=1000&color=667EEA&center=true&vCenter=true&multiline=true&repeat=true&width=850&height=120&lines=ğŸ“„+Upload+PDFs+%7C+Ask+Questions+%7C+Get+Answers;ğŸ§ +Powered+by+LangChain+%2B+OpenAI;ğŸ”+Vector+Search+with+Qdrant+Database;âš¡+Async+Processing+with+BullMQ+%26+Redis;ğŸš€+Built+with+Next.js+%26+Modern+Stack)](https://git.io/typing-svg)

<p align="center">
  <a href="https://github.com/SamratCrosiya/LangChain--Qdrant/stargazers">
    <img src="https://img.shields.io/github/stars/SamratCrosiya/LangChain--Qdrant?style=for-the-badge&logo=starship&color=C9CBFF&logoColor=D9E0EE&labelColor=302D41" alt="stars">
  </a>
  <a href="https://github.com/SamratCrosiya/LangChain--Qdrant/network/members">
    <img src="https://img.shields.io/github/forks/SamratCrosiya/LangChain--Qdrant?style=for-the-badge&logo=git&color=F38BA8&logoColor=D9E0EE&labelColor=302D41" alt="forks">
  </a>
  <a href="https://github.com/SamratCrosiya/LangChain--Qdrant/issues">
    <img src="https://img.shields.io/github/issues/SamratCrosiya/LangChain--Qdrant?style=for-the-badge&logo=gitbook&color=F2CDCD&logoColor=D9E0EE&labelColor=302D41" alt="issues">
  </a>
  <a href="https://github.com/SamratCrosiya/LangChain--Qdrant/blob/master/LICENSE">
    <img src="https://img.shields.io/github/license/SamratCrosiya/LangChain--Qdrant?style=for-the-badge&logo=opensourceinitiative&color=89DCEB&logoColor=D9E0EE&labelColor=302D41" alt="license">
  </a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Next.js_14-000000?style=for-the-badge&logo=nextdotjs&logoColor=white" alt="Next.js">
  <img src="https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white" alt="LangChain">
  <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI">
  <img src="https://img.shields.io/badge/Qdrant-DC244C?style=for-the-badge&logo=qdrant&logoColor=white" alt="Qdrant">
  <img src="https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white" alt="Redis">
  <img src="https://img.shields.io/badge/Clerk-6C47FF?style=for-the-badge&logo=clerk&logoColor=white" alt="Clerk">
</p>

<p align="center">
  <a href="#-quick-demo">ğŸ¥ Demo</a> â€¢
  <a href="#-features">âœ¨ Features</a> â€¢
  <a href="#-how-it-works">ğŸ” How It Works</a> â€¢
  <a href="#-installation">âš¡ Install</a> â€¢
  <a href="#-tech-stack">ğŸ’» Tech Stack</a> â€¢
  <a href="#-contributing">ğŸ¤ Contribute</a>
</p>

![Divider](https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif)

</div>

## ğŸ“– Table of Contents

- [ğŸ¯ Overview](#-overview)
- [ğŸŒŸ Key Features](#-key-features)
- [ğŸ¥ Quick Demo](#-quick-demo)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [ğŸ’» Tech Stack](#-tech-stack)
- [ğŸ” How It Works](#-how-it-works)
- [ğŸ“š Understanding RAG](#-understanding-rag)
- [âš¡ Installation](#-installation)
- [ğŸš€ Usage Guide](#-usage-guide)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ“ Learning Journey](#-learning-journey)
- [ğŸ›£ï¸ Roadmap](#ï¸-roadmap)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)
- [ğŸ‘¨â€ğŸ’» About Creator](#-about-creator)

---

## ğŸ¯ Overview

<div align="center">

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                   â•‘
â•‘        ğŸ“š  Chat With Your PDFs - RAG System in Action  ğŸ“š        â•‘
â•‘                                                                   â•‘
â•‘    Upload any PDF, ask questions, get intelligent answers        â•‘
â•‘    powered by LangChain, Qdrant, and OpenAI technology          â•‘
â•‘                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</div>

**LangChain + Qdrant RAG System** is my first deep dive into the world of **Retrieval-Augmented Generation (RAG)**. This project demonstrates how to build an intelligent document chat system that can understand and answer questions about your PDF documents using cutting-edge AI technology.

> **RAG (Retrieval-Augmented Generation)**: A technique where an AI model retrieves relevant information from a knowledge base before generating an answer, making responses more accurate and grounded in actual document content.

### ğŸ¯ What This Project Does

<table>
<tr>
<td align="center" width="25%">
<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Page%20with%20Curl.png" width="60"/>
<br><b>Upload PDFs</b>
<br><sub>Any document, any size</sub>
</td>
<td align="center" width="25%">
<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Magnifying%20Glass%20Tilted%20Left.png" width="60"/>
<br><b>Intelligent Search</b>
<br><sub>Vector-based retrieval</sub>
</td>
<td align="center" width="25%">
<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Robot.png" width="60"/>
<br><b>AI Answers</b>
<br><sub>Context-aware responses</sub>
</td>
<td align="center" width="25%">
<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Locked.png" width="60"/>
<br><b>Secure Auth</b>
<br><sub>Clerk authentication</sub>
</td>
</tr>
</table>

> **ğŸ’¡ My Learning Journey**: "This was my first time working with LangChain, vector databases, embedding algorithms, OpenAI APIs, Gemini APIs, and Next.js. Every concept was new, every challenge was a learning opportunity. The result? A fully functional RAG system that actually works!"

---

## ğŸŒŸ Key Features

<div align="center">

### ğŸ’ What Makes This Special

</div>

<table>
<tr>
<td width="50%" valign="top">

### ğŸ“„ **Smart PDF Processing**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Page%20Facing%20Up.png" width="50" align="left" style="margin-right: 10px"/>

Upload any PDF and let the system intelligently process it into searchable chunks.

**ğŸ¯ Processing Features:**
- âœ… Automatic text extraction from PDFs
- âœ… Intelligent document chunking
- âœ… Preserves document context
- âœ… Handles large documents (100+ pages)
- âœ… Asynchronous background processing
- âœ… Progress tracking and notifications

**ğŸ“Š What Happens:**
```
PDF Upload â†’ Text Extraction â†’ Smart Chunking
     â†“
Each chunk ~500 words with 50-word overlap
     â†“
Preserves context across boundaries
```

> **Chunking**: Breaking documents into smaller, overlapping pieces so the AI can find exactly the right information without losing context between sections.

</td>
<td width="50%" valign="top">

### ğŸ§  **Vector Embeddings Magic**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Crystal%20Ball.png" width="50" align="left" style="margin-right: 10px"/>

Convert text into mathematical vectors that capture semantic meaning.

**ğŸ” Embedding Features:**
- âœ… OpenAI's text-embedding-ada-002 model
- âœ… 1536-dimensional vector space
- âœ… Semantic similarity search
- âœ… Context-aware retrieval
- âœ… Multi-language support
- âœ… High accuracy matching

**ğŸ­ How It Works:**
```javascript
Text: "What is machine learning?"
  â†“ OpenAI Embedding Model
Vector: [0.023, -0.891, 0.445, ... 1536 dimensions]
  â†“ Stored in Qdrant
Ready for semantic search!
```

> **Embedding**: Converting text to numbers in a way that similar meanings have similar numbers, allowing the AI to find relevant content even if different words are used.

</td>
</tr>

<tr>
<td width="50%" valign="top">

### ğŸ” **Qdrant Vector Database**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Card%20File%20Box.png" width="50" align="left" style="margin-right: 10px"/>

Specialized database designed specifically for storing and searching vector embeddings.

**âš¡ Database Features:**
- âœ… Lightning-fast vector similarity search
- âœ… Stores millions of vectors efficiently
- âœ… Built-in filtering and metadata
- âœ… Docker-based deployment
- âœ… REST API interface
- âœ… Real-time indexing

**ğŸ“¦ Storage Structure:**
```python
Document Collection in Qdrant:
â”œâ”€ Vector 1 + Metadata (page 1, chunk 1)
â”œâ”€ Vector 2 + Metadata (page 1, chunk 2)
â”œâ”€ Vector 3 + Metadata (page 2, chunk 1)
â””â”€ ... (all document chunks)

Search Query â†’ Find Top 5 Similar Vectors â†’ Return Text
```

> **Vector Database**: Unlike traditional databases that search for exact matches, vector databases find the most *similar* items, perfect for AI-powered search.

</td>
<td width="50%" valign="top">

### âš¡ **Async Processing with BullMQ**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Travel%20and%20places/High%20Speed%20Train.png" width="50" align="left" style="margin-right: 10px"/>

Background job processing ensures the UI stays responsive while handling heavy tasks.

**ğŸ”§ Queue Features:**
- âœ… Background PDF processing
- âœ… Job retry on failure
- âœ… Progress tracking
- âœ… Concurrent job handling
- âœ… Redis-backed reliability
- âœ… Job prioritization

**ğŸ”„ Processing Flow:**
```
User uploads PDF
     â†“
Immediate response: "Processing started!"
     â†“
BullMQ Queue picks up job
     â†“
Worker processes in background
     â†“
User can continue browsing
     â†“
Notification when complete
```

> **BullMQ**: A job queue system that handles time-consuming tasks in the background, so users don't have to wait and the app stays fast and responsive.

</td>
</tr>

<tr>
<td width="50%" valign="top">

### ğŸ¤– **LangChain Orchestration**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Link.png" width="50" align="left" style="margin-right: 10px"/>

The glue that connects all the pieces together into a seamless RAG pipeline.

**ğŸ¯ LangChain Powers:**
- âœ… Document loading and parsing
- âœ… Text splitting strategies
- âœ… Vector store integration
- âœ… Retrieval chain setup
- âœ… LLM prompting templates
- âœ… Memory management

**ğŸ”— Chain Example:**
```javascript
const chain = RetrievalQAChain.from_llm({
  llm: new ChatOpenAI(),
  retriever: vectorStore.asRetriever(),
  returnSourceDocuments: true
});

// One line to create entire RAG pipeline!
```

> **LangChain**: A framework that makes it easy to build applications with LLMs by providing pre-built components for common tasks like document loading, splitting, and retrieval.

</td>
<td width="50%" valign="top">

### ğŸ” **Clerk Authentication**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Locked%20with%20Key.png" width="50" align="left" style="margin-right: 10px"/>

Enterprise-grade authentication to protect your AI application from misuse.

**ğŸ›¡ï¸ Security Features:**
- âœ… Email/password authentication
- âœ… Social login (Google, GitHub)
- âœ… Session management
- âœ… Protected API routes
- âœ… User profile management
- âœ… Usage tracking per user

**ğŸ‘¤ User Experience:**
```
Sign Up/Login â†’ Verified Session â†’ Access Dashboard
     â†“
All uploads tied to user account
     â†“
Personal document library
     â†“
Secure, isolated data
```

> **Clerk**: A complete authentication system that handles sign-ups, logins, and user management, so you can focus on building features instead of security.

</td>
</tr>
</table>

<div align="center">

### ğŸ“ **Additional Features**

<table>
<tr>
<td align="center">ğŸ’¬<br><b>Real-time Chat</b></td>
<td align="center">ğŸ“Š<br><b>Usage Analytics</b></td>
<td align="center">ğŸ¨<br><b>Modern UI</b></td>
<td align="center">ğŸ“±<br><b>Responsive Design</b></td>
<td align="center">ğŸŒ™<br><b>Dark Mode</b></td>
</tr>
</table>

</div>

---

## ğŸ¥ Quick Demo

<div align="center">

### ğŸ–¥ï¸ **Application Showcase**

<table>
<tr>
<td width="50%" align="center">
<img src="https://via.placeholder.com/500x300/667eea/ffffff?text=Upload+Dashboard" alt="Upload Dashboard" width="100%"/>
<br><b>ğŸ“¤ Upload Dashboard</b>
<br><sub>Drag & drop PDF â€¢ Processing status â€¢ File management</sub>
</td>
<td width="50%" align="center">
<img src="https://via.placeholder.com/500x300/764ba2/ffffff?text=Chat+Interface" alt="Chat Interface" width="100%"/>
<br><b>ğŸ’¬ AI Chat Interface</b>
<br><sub>Ask questions â€¢ Get answers â€¢ View sources</sub>
</td>
</tr>
<tr>
<td width="50%" align="center">
<img src="https://via.placeholder.com/500x300/10b981/ffffff?text=Vector+Search" alt="Vector Search" width="100%"/>
<br><b>ğŸ” Vector Search Results</b>
<br><sub>Relevant chunks â€¢ Similarity scores â€¢ Page references</sub>
</td>
<td width="50%" align="center">
<img src="https://via.placeholder.com/500x300/f59e0b/ffffff?text=Document+Library" alt="Document Library" width="100%"/>
<br><b>ğŸ“š Document Library</b>
<br><sub>All PDFs â€¢ Search & filter â€¢ Quick access</sub>
</td>
</tr>
</table>

### ğŸ¬ **Try It Live**

[![Live Demo](https://img.shields.io/badge/Demo-Try_It_Live-success?style=for-the-badge&logo=vercel&logoColor=white)](#)
[![Video Tutorial](https://img.shields.io/badge/Video-Watch_Tutorial-red?style=for-the-badge&logo=youtube&logoColor=white)](#)

</div>

---

## ğŸ—ï¸ System Architecture

<div align="center">

### **Complete RAG System Architecture**

```mermaid
graph TB
    subgraph "Frontend - Next.js UI"
        A[ğŸŒ User Interface]
        B[ğŸ“¤ Upload Component]
        C[ğŸ’¬ Chat Component]
    end
    
    subgraph "Authentication"
        D[ğŸ” Clerk Auth]
    end
    
    subgraph "Backend - Next.js API Routes"
        E[âš¡ Upload Endpoint]
        F[ğŸ’¬ Chat Endpoint]
        G[ğŸ“Š Status Endpoint]
    end
    
    subgraph "Queue System"
        H[ğŸ“® BullMQ Queue]
        I[âš™ï¸ Background Worker]
        J[ğŸ’¾ Redis Store]
    end
    
    subgraph "LangChain Pipeline"
        K[ğŸ“„ PDF Loader]
        L[âœ‚ï¸ Text Splitter]
        M[ğŸ§® OpenAI Embeddings]
        N[ğŸ”— Retrieval Chain]
    end
    
    subgraph "Storage Layer"
        O[ğŸ—„ï¸ Qdrant Vector DB]
        P[â˜ï¸ File Storage]
    end
    
    subgraph "AI Layer"
        Q[ğŸ¤– OpenAI LLM]
        R[ğŸ’¬ Gemini API]
    end
    
    A --> B
    A --> C
    B --> D
    C --> D
    D --> E
    D --> F
    
    E --> H
    H --> I
    I --> K
    K --> L
    L --> M
    M --> O
    
    C --> F
    F --> N
    N --> O
    N --> Q
    N --> R
    
    H --> J
    E --> P
    
    style O fill:#dc244c,stroke:#b81d3a,stroke-width:3px
    style Q fill:#412991,stroke:#2d1a64,stroke-width:3px
    style K fill:#1c3c3c,stroke:#152d2d,stroke-width:2px
    style D fill:#6c47ff,stroke:#5235cc,stroke-width:2px
```

</div>

### **ğŸ”„ Two Main Pipelines**

<table>
<tr>
<td width="50%" valign="top">

#### **A. Ingestion Pipeline** 
*Processing PDFs into searchable vectors*

```mermaid
sequenceDiagram
    participant User
    participant UI
    participant API
    participant Queue
    participant Worker
    participant LangChain
    participant OpenAI
    participant Qdrant
    
    User->>UI: Upload PDF
    UI->>API: POST /api/upload
    API->>Queue: Add job to BullMQ
    API->>UI: Job ID + Status
    UI->>User: "Processing..."
    
    Queue->>Worker: Pick up job
    Worker->>LangChain: Load PDF
    LangChain->>Worker: Extract text
    Worker->>LangChain: Split into chunks
    LangChain->>Worker: Text chunks
    
    loop For each chunk
        Worker->>OpenAI: Create embedding
        OpenAI->>Worker: Vector (1536 dims)
        Worker->>Qdrant: Store vector + text
    end
    
    Worker->>UI: Processing complete!
    UI->>User: "Ready to chat!"
```

**ğŸ“ Step-by-Step:**

1. **Upload** â†’ User selects PDF file
2. **Storage** â†’ File saved, job queued
3. **Worker** â†’ Background process starts
4. **Loading** â†’ PDF text extracted
5. **Chunking** â†’ Split into ~500 word pieces
6. **Embedding** â†’ Each chunk â†’ vector
7. **Storage** â†’ Vectors saved to Qdrant
8. **Complete** â†’ User notified

</td>
<td width="50%" valign="top">

#### **B. Retrieval Pipeline**
*Answering questions from PDFs*

```mermaid
sequenceDiagram
    participant User
    participant UI
    participant API
    participant LangChain
    participant Qdrant
    participant OpenAI
    
    User->>UI: Ask question
    UI->>API: POST /api/chat
    API->>LangChain: Initialize RAG chain
    
    LangChain->>OpenAI: Embed question
    OpenAI->>LangChain: Question vector
    
    LangChain->>Qdrant: Search similar vectors
    Qdrant->>LangChain: Top 5 relevant chunks
    
    LangChain->>OpenAI: Question + Context
    Note over LangChain,OpenAI: "Answer this question<br/>using these chunks"
    
    OpenAI->>LangChain: Generated answer
    LangChain->>API: Answer + sources
    API->>UI: Display response
    UI->>User: See answer + sources
```

**ğŸ“ Step-by-Step:**

1. **Question** â†’ User asks in chat
2. **Embed** â†’ Question â†’ vector
3. **Search** â†’ Find similar vectors in Qdrant
4. **Retrieve** â†’ Get top 5 relevant chunks
5. **Prompt** â†’ Combine question + chunks
6. **Generate** â†’ LLM creates answer
7. **Return** â†’ Answer + source citations
8. **Display** â†’ User sees response

</td>
</tr>
</table>

---

## ğŸ’» Tech Stack

<div align="center">

### **Core Technologies & Platforms**

</div>

### ğŸ¨ **Frontend Framework**

![Next.js](https://img.shields.io/badge/Next.js_14-000000?style=for-the-badge&logo=nextdotjs&logoColor=white)
![React](https://img.shields.io/badge/React_18-61DAFB?style=for-the-badge&logo=react&logoColor=black)
![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)
![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-06B6D4?style=for-the-badge&logo=tailwindcss&logoColor=white)
![Shadcn UI](https://img.shields.io/badge/Shadcn_UI-000000?style=for-the-badge&logo=shadcnui&logoColor=white)

> **Next.js**: Full-stack React framework handling both frontend UI and backend API routes in one unified application.

### ğŸ§  **AI & Machine Learning**

![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)
![Gemini](https://img.shields.io/badge/Google_Gemini-4285F4?style=for-the-badge&logo=google&logoColor=white)

> **LangChain**: The orchestration layer that connects document loading, embedding, storage, and retrieval into a seamless RAG pipeline.

### ğŸ—„ï¸ **Database & Storage**

![Qdrant](https://img.shields.io/badge/Qdrant-DC244C?style=for-the-badge&logo=qdrant&logoColor=white)
![Redis](https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

> **Qdrant**: Specialized vector database optimized for storing and searching through millions of high-dimensional embedding vectors.

### ğŸ” **Authentication & Security**

![Clerk](https://img.shields.io/badge/Clerk-6C47FF?style=for-the-badge&logo=clerk&logoColor=white)

> **Clerk**: Complete authentication platform providing sign-up, login, session management, and user protection to prevent AI misuse.

### âš™ï¸ **Background Processing**

![BullMQ](https://img.shields.io/badge/BullMQ-CC0000?style=for-the-badge&logo=bull&logoColor=white)
![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)

> **BullMQ**: Robust job queue system built on Redis for handling asynchronous PDF processing tasks in the background.

---

### ğŸ“¦ **Essential Dependencies**

```json
{
  "dependencies": {
    "next": "^14.0.0",
    "react": "^18.0.0",
    "@clerk/nextjs": "^4.27.0",
    "langchain": "^0.1.0",
    "openai": "^4.20.0",
    "@google/generative-ai": "^0.1.0",
    "@qdrant/js-client-rest": "^1.7.0",
    "bullmq": "^4.15.0",
    "ioredis": "^5.3.2",
    "pdf-parse": "^1.1.1",
    "tailwindcss": "^3.4.0",
    "@radix-ui/react-*": "latest"
  }
}
```

---

## ğŸ” How It Works

<div align="center">

### **Deep Dive into the RAG System**

</div>

### ğŸ“š Understanding RAG (Retrieval-Augmented Generation)

<table>
<tr>
<td width="50%">

**ğŸ¤” The Problem:**

Traditional LLMs like ChatGPT have limitations:
- âŒ Don't know about your specific documents
- âŒ Can't access real-time information
- âŒ May hallucinate facts
- âŒ Limited by training data cutoff

**Example:**
```
User: "What's in section 5 of my contract?"
Normal LLM: "I don't have access to your contract"
```

</td>
<td width="50%">

**âœ… The RAG Solution:**

RAG combines retrieval + generation:
- âœ… Searches your actual documents
- âœ… Retrieves relevant sections
- âœ… Generates answers based on YOUR data
- âœ… Provides source citations

**Example:**
```
User: "What's in section 5 of my contract?"
RAG System: "Section 5 states: [exact quote]
Source: contract.pdf, page 8"
```

</td>
</tr>
</table>

---

### ğŸ”¢ **The Embedding Process**

Embeddings convert text into numbers that capture meaning:

```javascript
// Text to Vector Conversion
const text = "Machine learning is a subset of AI";

// Send to OpenAI
const embedding = await openai.embeddings.create({
  model: "text-embedding-ada-002",
  input: text
});

// Result: 1536-dimensional vector
[0.023, -0.891, 0.445, 0.789, ..., 0.234]
//  â†‘        â†‘        â†‘       â†‘          â†‘
// Each dimension captures different semantic features

// Similar meanings = Similar vectors
"AI and machine learning" â†’ [0.025, -0.888, 0.441, ...]
"Dogs and cats" â†’           [0.612, 0.234, -0.891, ...]
//                            â†‘ Very different numbers!
```

**ğŸ¯ Why This Matters:**
- Similar concepts have similar vectors
- Allows semantic search (meaning-based, not keyword-based)
- Finds relevant content even with different wording

---

### ğŸ” **Vector Similarity Search**

How Qdrant finds relevant document chunks:

```python
# User asks a question
question = "What are the payment terms?"

# 1. Convert question to vector
question_vector = embed(question)  # [0.234, -0.567, ...]

# 2. Search Qdrant for similar vectors
results = qdrant.search(
    collection_name="my_documents",
    query_vector=question_vector,
    limit=5  # Top 5 most similar
)

# 3. Results ranked by similarity
[
    {text: "Payment is due within 30 days...", score: 0.92},
    {text: "Invoice terms include...", score: 0.87},
    {text: "Monthly billing cycle...", score: 0.81},
    ...
]
```

**ğŸ“Š Similarity Score:**
- 1.0 = Perfect match
- 0.8-1.0 = Highly relevant
- 0.6-0.8 = Somewhat relevant  
- <0.6 = Not relevant (ignored)

---

### ğŸ”— **LangChain Pipeline in Action**

How LangChain orchestrates the entire RAG workflow:

```javascript
import { RetrievalQAChain } from "langchain/chains";
import { ChatOpenAI } from "langchain/chat_models/openai";
import { QdrantVectorStore } from "langchain/vectorstores/qdrant";

// Step 1: Setup the components
const llm = new ChatOpenAI({
  modelName: "gpt-4",
  temperature: 0.7
});

const vectorStore = await QdrantVectorStore.fromExistingCollection(
  embeddings,
  { collectionName: "documents" }
);

// Step 2: Create the RAG chain (this is the magic!)
const chain = RetrievalQAChain.fromLLM(
  llm,
  vectorStore.asRetriever(5), // Get top 5 chunks
  {
    returnSourceDocuments: true, // Show where answer came from
    verbose: true
  }
);

// Step 3: Ask a question
const response = await chain.call({
  query: "What are the payment terms?"
});

console.log(response.text); // AI-generated answer
console.log(response.sourceDocuments); // Citations
```

**ğŸ¯ What Just Happened:**
1. LangChain retrieved 5 relevant chunks from Qdrant
2. Combined them into a context prompt
3. Sent to OpenAI with your question
4. Got back an answer WITH sources!

---

## âš¡ Installation

### ğŸ“‹ **Prerequisites**

```bash
âœ“ Node.js 18.x or higher
âœ“ npm or yarn package manager
âœ“ Docker Desktop (for Qdrant & Redis)
âœ“ OpenAI API key
âœ“ Clerk account (free tier works)
âœ“ 8GB+ RAM recommended
âœ“ 5GB+ free disk space
```

### ğŸš€ **Quick Start Guide**

<table>
<tr>
<td width="50%" valign="top">

#### **Step 1: Clone & Install**

```bash
# Clone the repository
git clone https://github.com/SamratCrosiya/LangChain--Qdrant.git
cd LangChain--Qdrant

# Install dependencies
npm install
# or
yarn install

# Time: 2-3 minutes
```

**ğŸ“¦ What gets installed:**
- Next.js framework
- LangChain libraries
- OpenAI SDK
- Qdrant client
- BullMQ & Redis
- Clerk authentication
- UI components (Tailwind, Shadcn)

</td>
<td width="50%" valign="top">

#### **Step 2: Setup Docker Services**

```bash
# Start Qdrant (Vector Database)
docker run -d \
  --name qdrant \
  -p 6333:6333 \
  -p 6334:6334 \
  -v $(pwd)/qdrant_storage:/qdrant/storage \
  qdrant/qdrant:latest

# Start Redis (Queue Backend)
docker run -d \
  --name redis \
  -p 6379:6379 \
  redis:alpine

# Verify services are running
docker ps
```

**âœ… Expected output:**
```
CONTAINER ID   IMAGE           STATUS
abc123...      qdrant/qdrant   Up 2 seconds
def456...      redis:alpine    Up 1 second
```

</td>
</tr>
</table>

### ğŸ”‘ **Step 3: Environment Configuration**

Create a `.env.local` file in the root directory:

```bash
# OpenAI Configuration
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# Google Gemini (Optional Alternative)
GOOGLE_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxx

# Clerk Authentication
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_xxxxxxxx
CLERK_SECRET_KEY=sk_test_xxxxxxxxxxxxxxxx
NEXT_PUBLIC_CLERK_SIGN_IN_URL=/sign-in
NEXT_PUBLIC_CLERK_SIGN_UP_URL=/sign-up

# Qdrant Configuration
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=  # Leave empty for local

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Application Settings
NEXT_PUBLIC_APP_URL=http://localhost:3000
NODE_ENV=development
```

### âš™ï¸ **Step 4: Run the Application**

```bash
# Development mode with hot reload
npm run dev
# or
yarn dev

# Open your browser
http://localhost:3000

# You should see the login screen!
```

### ğŸ§ª **Verify Installation**

Run these checks to ensure everything works:

```bash
# Test 1: Check Next.js server
curl http://localhost:3000
# Expected: HTML response

# Test 2: Check Qdrant
curl http://localhost:6333/collections
# Expected: {"result":{"collections":[]}}

# Test 3: Check Redis
docker exec redis redis-cli PING
# Expected: PONG

# Test 4: Check OpenAI (in browser console)
# Upload a test PDF and verify processing starts
```

---

## ğŸš€ Usage Guide

<div align="center">

### **Complete User Journey**

</div>

### ğŸ“ **Step-by-Step Tutorial**

<table>
<tr>
<td width="33%" align="center">

**1ï¸âƒ£ Sign Up / Login**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Locked%20with%20Key.png" width="60"/>

```
Visit localhost:3000
    â†“
Click "Sign Up"
    â†“
Enter email/password
    â†“
Verify email
    â†“
Access dashboard
```

</td>
<td width="33%" align="center">

**2ï¸âƒ£ Upload PDF**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Objects/Page%20Facing%20Up.png" width="60"/>

```
Click "Upload PDF"
    â†“
Select file
    â†“
Processing starts
    â†“
Progress bar shows
    â†“
"Ready to chat!"
```

</td>
<td width="33%" align="center">

**3ï¸âƒ£ Ask Questions**

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Thinking%20Face.png" width="60"/>

```
Type your question
    â†“
Press Enter
    â†“
AI searches vectors
    â†“
Generates answer
    â†“
See sources!
```

</td>
</tr>
</table>

### ğŸ¯ **Real-World Usage Examples**

<details>
<summary><b>ğŸ“š Example 1: Research Paper Analysis</b></summary>

```
Upload: "Machine_Learning_Research_2024.pdf"

Question: "What are the key findings in section 3?"

AI Response:
"Section 3 presents three key findings:
1. Deep learning models showed 23% improvement
2. Transfer learning reduced training time by 40%
3. Ensemble methods achieved state-of-the-art results

Source: Machine_Learning_Research_2024.pdf, Pages 8-12"
```

</details>

<details>
<summary><b>ğŸ“„ Example 2: Legal Contract Review</b></summary>

```
Upload: "Service_Agreement_2024.pdf"

Question: "What are the termination clauses?"

AI Response:
"The contract includes the following termination clauses:
- Either party may terminate with 30 days written notice
- Immediate termination allowed for material breach
- Automatic renewal unless cancelled 60 days before expiry

Source: Service_Agreement_2024.pdf, Section 8.2, Page 15"
```

</details>

<details>
<summary><b>ğŸ“Š Example 3: Financial Report Summary</b></summary>

```
Upload: "Q4_Financial_Report.pdf"

Question: "Summarize the revenue growth"

AI Response:
"Q4 2024 revenue grew 18% year-over-year to $2.4M:
- Product sales: +25% ($1.8M)
- Services: +8% ($600K)
Main drivers were new customer acquisition (+320 customers)
and increased average order value (+12%)

Source: Q4_Financial_Report.pdf, Executive Summary, Pages 2-4"
```

</details>

### ğŸ’¡ **Pro Tips**

```
âœ… DO:
- Ask specific questions
- Reference sections/topics
- Upload clear, text-based PDFs
- Use follow-up questions
- Check source citations

âŒ DON'T:
- Upload scanned images (use OCR first)
- Ask questions outside the document
- Expect exact quotes (it paraphrases)
- Upload very large files (>50MB) without splitting
```

---

## ğŸ“ Project Structure

```
LangChain--Qdrant/
â”‚
â”œâ”€â”€ ğŸ“ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ ğŸ“ (auth)/                   # Authentication routes
â”‚   â”‚   â”œâ”€â”€ ğŸ“ sign-in/
â”‚   â”‚   â”‚   â””â”€â”€ [[...sign-in]]/
â”‚   â”‚   â”‚       â””â”€â”€ page.tsx
â”‚   â”‚   â””â”€â”€ ğŸ“ sign-up/
â”‚   â”‚       â””â”€â”€ [[...sign-up]]/
â”‚   â”‚           â””â”€â”€ page.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api/                      # API Routes
â”‚   â”‚   â”œâ”€â”€ ğŸ“ upload/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts             # PDF upload endpoint
â”‚   â”‚   â”œâ”€â”€ ğŸ“ chat/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts             # Chat endpoint
â”‚   â”‚   â””â”€â”€ ğŸ“ documents/
â”‚   â”‚       â””â”€â”€ route.ts             # Document management
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ dashboard/                # Main app pages
â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Dashboard home
â”‚   â”‚   â”œâ”€â”€ layout.tsx               # Dashboard layout
â”‚   â”‚   â””â”€â”€ ğŸ“ [documentId]/
â”‚   â”‚       â””â”€â”€ page.tsx             # Chat with specific doc
â”‚   â”‚
â”‚   â”œâ”€â”€ layout.tsx                   # Root layout
â”‚   â”œâ”€â”€ page.tsx                     # Landing page
â”‚   â””â”€â”€ globals.css                  # Global styles
â”‚
â”œâ”€â”€ ğŸ“ components/                   # React Components
â”‚   â”œâ”€â”€ ğŸ“ ui/                       # Shadcn UI components
â”‚   â”‚   â”œâ”€â”€ button.tsx
â”‚   â”‚   â”œâ”€â”€ card.tsx
â”‚   â”‚   â”œâ”€â”€ input.tsx
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ upload-zone.tsx              # Drag & drop upload
â”‚   â”œâ”€â”€ chat-interface.tsx           # Chat UI
â”‚   â”œâ”€â”€ document-list.tsx            # Document library
â”‚   â”œâ”€â”€ message-bubble.tsx           # Chat messages
â”‚   â””â”€â”€ processing-status.tsx        # Upload progress
â”‚
â”œâ”€â”€ ğŸ“ lib/                          # Core Libraries
â”‚   â”œâ”€â”€ ğŸ“ langchain/
â”‚   â”‚   â”œâ”€â”€ embeddings.ts            # OpenAI embeddings
â”‚   â”‚   â”œâ”€â”€ splitter.ts              # Text chunking
â”‚   â”‚   â”œâ”€â”€ vectorstore.ts           # Qdrant integration
â”‚   â”‚   â””â”€â”€ chain.ts                 # RAG chain setup
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ queue/
â”‚   â”‚   â”œâ”€â”€ worker.ts                # BullMQ worker
â”‚   â”‚   â”œâ”€â”€ jobs.ts                  # Job definitions
â”‚   â”‚   â””â”€â”€ redis.ts                 # Redis connection
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ db/
â”‚   â”‚   â”œâ”€â”€ qdrant.ts                # Qdrant client
â”‚   â”‚   â””â”€â”€ schema.ts                # Data schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ clerk.ts                     # Clerk auth helpers
â”‚   â””â”€â”€ utils.ts                     # Utility functions
â”‚
â”œâ”€â”€ ğŸ“ workers/                      # Background Workers
â”‚   â””â”€â”€ pdf-processor.ts             # PDF ingestion worker
â”‚
â”œâ”€â”€ ğŸ“ types/                        # TypeScript Types
â”‚   â”œâ”€â”€ document.ts
â”‚   â”œâ”€â”€ message.ts
â”‚   â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ ğŸ“ public/                       # Static Assets
â”‚   â”œâ”€â”€ logo.svg
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ ğŸ“ qdrant_storage/               # Qdrant data (gitignored)
â”œâ”€â”€ ğŸ“ uploads/                      # Temporary uploads (gitignored)
â”‚
â”œâ”€â”€ ğŸ“„ package.json                  # Dependencies
â”œâ”€â”€ ğŸ“„ tsconfig.json                 # TypeScript config
â”œâ”€â”€ ğŸ“„ tailwind.config.ts            # Tailwind config
â”œâ”€â”€ ğŸ“„ next.config.js                # Next.js config
â”œâ”€â”€ ğŸ“„ .env.local                    # Environment variables
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git ignore rules
â”œâ”€â”€ ğŸ“„ README.md                     # This file
â””â”€â”€ ğŸ“„ docker-compose.yml            # Docker services

```

### **Key Files Explained**

| File/Folder | Purpose | Technology |
|-------------|---------|------------|
| `app/api/upload/route.ts` | Handles PDF uploads | Next.js API Route |
| `lib/langchain/chain.ts` | RAG pipeline setup | LangChain |
| `workers/pdf-processor.ts` | Background PDF processing | BullMQ Worker |
| `lib/db/qdrant.ts` | Vector database client | Qdrant JS Client |
| `components/chat-interface.tsx` | Chat UI component | React + Tailwind |

---

## ğŸ“ Learning Journey

<div align="center">

### **My First-Time Experience with These Technologies**

</div>

### ğŸ“š **What I Learned**

<table>
<tr>
<td width="50%" valign="top">

### ğŸ§  **LangChain Concepts**

**Before:** "What is LangChain?"  
**After:** Expert in building RAG pipelines!

**Key Learnings:**
- âœ… Document loaders and parsers
- âœ… Text splitting strategies
- âœ… Embedding generation
- âœ… Vector store integration
- âœ… Retrieval chains
- âœ… Prompt engineering

**ğŸ’¡ Biggest "Aha!" Moment:**
```javascript
// I thought I needed to manually:
// 1. Load PDF
// 2. Split text
// 3. Create embeddings
// 4. Store in DB
// 5. Search
// 6. Prompt LLM

// LangChain does ALL of this:
const chain = RetrievalQAChain.fromLLM(llm, retriever);
// Mind = Blown! ğŸ¤¯
```

</td>
<td width="50%" valign="top">

### ğŸ—„ï¸ **Vector Databases**

**Before:** "SQL queries are all I need"  
**After:** Understanding semantic search!

**Key Learnings:**
- âœ… What embeddings actually are
- âœ… Cosine similarity calculations
- âœ… HNSW indexing algorithms
- âœ… Collection management
- âœ… Metadata filtering
- âœ… Performance optimization

**ğŸ’¡ Mind-Blowing Realization:**
```
Traditional DB:
SELECT * FROM docs WHERE title = "exact match"
âŒ Finds nothing if wording different

Vector DB:
search("What are payment terms?")
âœ… Finds "billing schedule", "invoice policy"
   because they're semantically similar!
```

</td>
</tr>

<tr>
<td width="50%" valign="top">

### ğŸ”— **API Integration**

**Before:** Never used OpenAI or Gemini APIs  
**After:** Confidently working with multiple LLMs!

**Key Learnings:**
- âœ… API authentication & keys
- âœ… Rate limiting handling
- âœ… Token management
- âœ… Cost optimization
- âœ… Error handling
- âœ… Fallback strategies

**ğŸ’° Cost Awareness:**
```
Embedding 1 page PDF:
~500 tokens Ã— $0.0001/1K = $0.00005

Answering 1 question:
~2000 tokens Ã— $0.002/1K = $0.004

100 questions/day = $0.40/day = $12/month
(Optimized with caching!)
```

</td>
<td width="50%" valign="top">

### âš¡ **Async Processing**

**Before:** Everything ran synchronously  
**After:** Master of background jobs!

**Key Learnings:**
- âœ… Job queues with BullMQ
- âœ… Redis as message broker
- âœ… Worker processes
- âœ… Progress tracking
- âœ… Error retry logic
- âœ… Job prioritization

**ğŸ¯ Why It Matters:**
```
Without Queue:
User uploads 50-page PDF
    â†“
Waits 2 minutes... ğŸ˜´
    â†“
Browser might timeout âŒ

With BullMQ:
User uploads PDF
    â†“
Immediate response: "Processing!" âœ…
    â†“
Works in background
    â†“
User gets notification when done ğŸ‰
```

</td>
</tr>
</table>

### ğŸ“ˆ **Skills Growth Timeline**

```mermaid
timeline
    title My RAG Development Journey
    section Week 1-2 : Basics
        Day 1-3 : Next.js setup
               : Understanding RAG concept
        Day 4-7 : LangChain tutorials
               : First PDF loading test
        Day 8-14 : OpenAI API integration
                : Embedding experiments
    section Week 3-4 : Core Features
        Day 15-21 : Qdrant setup
                 : Vector storage working
                 : First successful search!
        Day 22-28 : BullMQ implementation
                 : Background processing
                 : Queue system complete
    section Week 5-6 : Polish
        Day 29-35 : Clerk authentication
                 : UI/UX improvements
        Day 36-42 : Testing & debugging
                 : Performance optimization
                 : Documentation
    section Week 7 : Launch
        Day 43-45 : Final testing
                 : Deployment prep
        Day 46-49 : First users!
                 : Bug fixes
                 : This README! ğŸ‰
```

---

## ğŸ›£ï¸ Roadmap

### **Planned Features**

<table>
<tr>
<td width="25%">

**ğŸ¯ Phase 1**
*Current*

- [x] PDF upload
- [x] Vector search
- [x] Chat interface
- [x] User auth
- [x] Basic RAG

</td>
<td width="25%">

**ğŸš€ Phase 2**
*Q2 2025*

- [ ] Multi-file chat
- [ ] OCR support
- [ ] Export chat
- [ ] Shared docs
- [ ] API access

</td>
<td width="25%">

**ğŸ’ Phase 3**
*Q3 2025*

- [ ] Teams/workspaces
- [ ] Advanced filters
- [ ] Analytics dashboard
- [ ] Custom prompts
- [ ] Webhooks

</td>
<td width="25%">

**ğŸŒŸ Phase 4**
*Q4 2025*

- [ ] Mobile app
- [ ] Voice queries
- [ ] Auto-summarize
- [ ] Integrations
- [ ] Enterprise

</td>
</tr>
</table>

### **Feature Requests**

Have ideas? Open an issue with the `enhancement` label!

Popular requests:
- ğŸ“Š Excel/CSV support
- ğŸ¤ Voice input
- ğŸŒ Multi-language
- ğŸ“± Mobile apps
- ğŸ”Œ Zapier integration

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

### **How to Contribute**

1. **Fork the Repository**
   ```bash
   git clone https://github.com/SamratCrosiya/LangChain--Qdrant.git
   ```

2. **Create a Feature Branch**
   ```bash
   git checkout -b feature/AmazingFeature
   ```

3. **Make Your Changes**
   - Follow the existing code style
   - Add tests if applicable
   - Update documentation

4. **Commit Your Changes**
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```

5. **Push to Branch**
   ```bash
   git push origin feature/AmazingFeature
   ```

6. **Open a Pull Request**

### **Contribution Guidelines**

- Write clear commit messages
- Follow TypeScript best practices
- Add comments for complex logic
- Test before submitting
- Update README if needed

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License - Free to use, modify, and distribute!
```

---

## ğŸ‘¨â€ğŸ’» About Creator

<div align="center">

**Samrat Crosiya**

*Full-Stack Developer | AI Enthusiast | First-Time RAG Builder*

[![GitHub](https://img.shields.io/badge/GitHub-@SamratCrosiya-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/SamratCrosiya)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](#)
[![Twitter](https://img.shields.io/badge/Twitter-Follow-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](#)
[![Portfolio](https://img.shields.io/badge/Portfolio-Visit-FF6B6B?style=for-the-badge&logo=google-chrome&logoColor=white)](#)

</div>

### ğŸ’­ **Creator's Note**

> "This project represents my journey into the fascinating world of RAG systems and vector databases. Every concept was new to me - from understanding embeddings to implementing async job queues. The challenges were real, but so was the learning. If you're starting your AI journey, remember: every expert was once a beginner. Keep building, keep learning! ğŸš€"

---

## ğŸ™ Acknowledgments

**Special Thanks To:**

- **ğŸ¤— Hugging Face** - For making LangChain accessible
- **ğŸ”´ Qdrant** - For their excellent vector database
- **ğŸ§  OpenAI** - For powerful embedding & LLM APIs
- **âš¡ Vercel** - For Next.js and deployment platform
- **ğŸ” Clerk** - For seamless authentication
- **ğŸ“š Community** - Stack Overflow, Reddit, Discord helpers

**Resources That Helped:**
- [LangChain Documentation](https://docs.langchain.com)
- [Qdrant Tutorials](https://qdrant.tech/documentation/)
- [OpenAI Cookbook](https://cookbook.openai.com)
- [Next.js Docs](https://nextjs.org/docs)

---

<div align="center">

![Footer](https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=100&section=footer)

### â­ **If you found this helpful, please give it a star!** â­

*Built with â¤ï¸ and lots of â˜• by Samrat Crosiya*

**Made with**: LangChain â€¢ Qdrant â€¢ OpenAI â€¢ Next.js â€¢ Love for AI

</div>
